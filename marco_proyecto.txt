Entendimiento del Negocio y Carga de Textos
Desarrollado por:

* Manuel Huertas    manuelhuertasfl@gmail.com
* Daniel Salgado    daniamcsf18@gmail.com
* David Cristancho  dcristancho@unal.edu.co
1. Marco de Proyecto
Normalmente, se suele construir un marco de proyecto para mostrar los resultados del entendimiento del negocio, es decir, debemos dar respuesta a los siguientes elementos:

1.1. Trasfondo del Negocio
En la actualidad, gracias a Internet, se han desarrollado diversas formas de conectarse y comunicarse con personas de todo el mundo, desde las redes sociales hasta los videojuegos en línea, donde es posible interactuar tanto para obtener información y conocimiento como para disfrutar de momentos de entretenimiento. Por esta razón, en los últimos años, cada vez más empresas han estado dispuestas a ingresar al mundo digital debido a la gran cantidad de usuarios que utilizan estas plataformas. Esto, a su vez, ha incrementado las comunidades virtuales y fortalecido los lazos resultantes.

Sin embargo, también se ha observado un aumento en la violencia o toxicidad, 
como se refleja en diversas encuestas. 
Según una encuesta realizada por el centro de investigación Pew Research Center, 
el 40% de los encuestados manifestó haber sido víctima de violencia o toxicidad en las redes, 
siendo con frecuencia objeto de violencia sexual o acoso. Además, 
los encuestados informan con mayor frecuencia sobre este tipo de comportamientos, 
como se ha registrado entre 2014 y 2020.[1].

Por esta razón las empresas dueñas de estos espacios de interacción tienen la necesidad de 
usar filtros que permitan a sus usuarios compartir en el mundo digital sin estar expuestos 
a acoso por parte de otros, lo que afecta negativamente la experiencia que proveen. 
Empresas como Jigsaw y Google, ambas subsidiarias de Alphabet, han realizado esfuerzos para mitigar esta problemática. Por lo cual se han desarrollado filtros que permiten distinguir mensajes de odio que se reproducen en las redes con el fin de sancionar o limitar el acceso de usuarios que recurren a estas prácticas, no obstante los filtros a menudo fallan y enmarcan como discursos de odio mensajes que en su fondo no lo son, llevando a falsos positivos y posibles sanciones a usuarios que no están infringiendo las reglas de la comunidad, y así afectando la experiencia en general de todos modos.

Es por esto que el presente trabajo busca identificar los mensajes violentos o de acoso que afectan estas comunidades, a la vez que se mantiene la calidad de la experiencia para los usuarios de forma que se permita tener comunidades y espacios seguros que no se vean afectados por filtros sesgados, con altos niveles de falsos positivos.

1.2. Alcance
Para aliviar los problemas de toxicidad en las redes, este proyecto tiene como objetivo desarrollar un modelo capaz de clasificar los comentarios tóxicos, de interacciones en línea, que permita a las empresas, como Jigsaw y Google que tienen aplicaciones con interacción de usuarios, reconocer de una manera efectiva los niveles de violencia en redes, y que controle los falsos positivos que generan los filtros tradicionales. Por lo tanto el modelo debe ser sensible a diferentes contextos y debe poder distinguir los discursos de odio de los mensajes donde solo se mencionan palabras que sin serlo están asociadas a discursos de odio, como la palabra gay en inglés, o retrazo en español.

1.3. Plan
Puede agregar una lista de actividades con tiempos estimados, un diagrama de Gantt o integrar alguna herramienta de gestión de proyectos para mostrar la planeación del proyecto.

Fechas	Actividades
6 de Mayo - 11 de mayo	Entendimiento de negocio y carga de los datos.
13 de Mayo - 17 de Mayo	Recopilación y limpieza de un conjunto de datos diverso y representativo.
20 de Marzo - 24 de Mayo	Desarrollo de modelos de NLP que puedan reconocer diferentes formas y subtipos de toxicidad en los comentarios.
27 de Marzo - 31 de Mayo	Evaluación y optimización continua del modelo utilizando métricas específicas para medir el sesgo no intencionado y la precisión en la detección de toxicidad.
2. Definición del Corpus
El corpus a usar para el desarrollo del proyecto proviene de Kaggle y se encuentra con el nombre de “Jigsaw Unintended Bias in Toxicity Classification” (link a Kaggle).

Este es un dataset con aproximadamente 1.97 millones comentarios de la plataforma Civil Comments (más información), creados entre 2015 y 2017 por usuarios angloparlantes.

La columna principal del corpus es comment_text, que incluye el texto de cada comentario. Cada comentario está acompañado por una etiqueta principal de toxicidad (target), un número de 0 a 1, que indica la proporción de evaluadores que consideraron el comentario como tóxico. Además, el conjunto de datos incluye etiquetas para subtipos de toxicidad como severe_toxicity, obscene, threat, insult, identity_attack y sexual_explicit.

El conjunto de datos también incluye atributos de identidad, según sean mencionadas en el comentario correspondiente. Estos atributos abarcan categorías como género (male, female, transgender, other_gender), orientación sexual (heterosexual, homosexual_gay_or_lesbian, bisexual, other_sexual_orientation), religión (christian, jewish, muslim, hindu, buddhist, atheist, other_religion), raza o etnicidad (black, white, asian, latino, other_race_or_ethnicity), y discapacidad (physical_disability, intellectual_or_learning_disability, psychiatric_or_mental_illness, other_disability).

Además el corpus se encuentra particionado en los conjuntos de entrenamiento y prueba. El primero cuenta con 1'804.874 entradas, mientras que la partición de prueba tiene un total de 97.320 filas (Aunque no se hará uso de todas ya que el corpus es de tamaño considerable).

Algunos ejemplos del dataset:

Ejemplo 1
Comentario: i'm a white woman in my late 60's and believe me, they are not too crazy about me either!!
Etiquetas de toxicidad: All 0.0 Etiquetas de mención de identidades: female: 1.0, white: 1.0 (all others 0.0)

* Ejemplo 2
Comentario: Continue to stand strong LGBT community. Yes, indeed, you'll overcome and you have.

Etiqueta de toxicidad: All 0.0 Etiquetas de mención de identidades: homosexual_gay_or_lesbian: 0.8, bisexual: 0.6, transgender: 0.3 (all others 0.0)


El dataset se encuentra disponible en la plataforma de Kaggle, bajo el título mencionado anteriormente, y también fué subido a Google Drive como un archiv
